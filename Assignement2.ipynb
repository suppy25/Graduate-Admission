{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This dataset is created for prediction of Graduate Admissions from an Indian perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains several parameters which are considered important during the application for Masters Programs.\n",
    "The parameters included are :\n",
    "\n",
    "* GRE Scores ( out of 340 )\n",
    "* TOEFL Scores ( out of 120 )\n",
    "* University Rating ( out of 5 )\n",
    "* Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
    "* Undergraduate GPA ( out of 10 )\n",
    "* Research Experience ( either 0 or 1 )\n",
    "* Chance of Admit ( ranging from 0 to 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Serial No.', 'GRE Score', 'TOEFL Score', ..., 'CGPA',\n",
       "        'Research', 'Chance of Admit'],\n",
       "       ['1', '337', '118', ..., '9.65', '1', '0.92'],\n",
       "       ['2', '324', '107', ..., '8.87', '1', '0.76'],\n",
       "       ...,\n",
       "       ['398', '330', '116', ..., '9.45', '1', '0.91'],\n",
       "       ['399', '312', '103', ..., '8.78', '0', '0.67'],\n",
       "       ['400', '333', '117', ..., '9.66', '1', '0.95']], dtype='<U17')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.genfromtxt('Admission_Predict.csv',delimiter = ',', dtype=str);\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GRE Score' 'TOEFL Score' 'University Rating' 'SOP' 'LOR ' 'CGPA'\n",
      " 'Research' 'Chance of Admit']\n",
      "[[337.   118.     4.   ...   9.65   1.     0.92]\n",
      " [324.   107.     4.   ...   8.87   1.     0.76]\n",
      " [316.   104.     3.   ...   8.     1.     0.72]\n",
      " ...\n",
      " [330.   116.     4.   ...   9.45   1.     0.91]\n",
      " [312.   103.     3.   ...   8.78   0.     0.67]\n",
      " [333.   117.     4.   ...   9.66   1.     0.95]]\n"
     ]
    }
   ],
   "source": [
    "headers = df[0,1:]; # TO not take serial no\n",
    "print(headers)\n",
    "data = np.array(df[1:,1:], dtype=float); # This will take from the GRE Score\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = (data-np.mean(data, axis = 0))/np.std(data, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y from data\n",
    "\n",
    "y_label = 'Chance of Admit';\n",
    "y_index = np.where(headers == y_label)[0][0];\n",
    "y = data_norm[:,y_index];\n",
    "\n",
    "# Extract x from data\n",
    "\n",
    "X = data_norm[:,0:y_index];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert column of 1's for intercept column\n",
    "X = np.insert(X, 0, 1, axis=1) # added the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.76210664 1.74697064 0.79882862 1.09386422 1.16732114\n",
      " 1.76481828 0.90911166]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "n = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partion data into training and test datasets\n",
    "\n",
    "idx = np.arange(0,m)\n",
    "random.shuffle(idx)\n",
    "\n",
    "percent_train = .6\n",
    "m_train = int(m * percent_train)\n",
    "train_idx = idx[0:m_train]\n",
    "test_idx = idx[m_train:m+1]\n",
    "X_train = data[train_idx,1:y_index];\n",
    "X_test = data[test_idx,1:y_index];\n",
    "\n",
    "y_train = data[train_idx,y_index];\n",
    "y_test = data[test_idx,y_index];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function normalized by number of examples\n",
    "\n",
    "def H(theta,X,y):\n",
    "    return 1 / 2 / X.shape[1] * (h(X,theta)-y).T.dot(h(X,theta)-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.70408612e-16,  1.39783600e-01,  1.24258432e-01,  4.58476504e-02,\n",
       "       -2.33355774e-02,  1.40830779e-01,  4.97342141e-01,  8.57053356e-02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve the normal equations\n",
    "\n",
    "def regress(X, y):\n",
    "    cov = np.dot(X.T, X)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    theta = np.dot(cov_inv, np.dot(X.T, y))\n",
    "    return theta\n",
    "regress(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function normalized by number of examples\n",
    "\n",
    "def J(theta,X,y):\n",
    "    return 1 / 2 / X.shape[1] * (h(X,theta)-y).T.dot(h(X,theta)-y)\n",
    "\n",
    "# Get design matrix for polynomial model of degree d\n",
    "\n",
    "def x_polynomial(x, d):\n",
    "    a = np.ones((x.shape[0], 1))    \n",
    "    for i in range(d):\n",
    "        a = np.concatenate((a,x**(i+1)), axis = 1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models of degree 1 to max_degree\n",
    "\n",
    "max_degree = 2\n",
    "\n",
    "J_train = np.zeros(max_degree)\n",
    "J_test = np.zeros(max_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 8)\n",
      "(80, 8)\n",
      "(320,)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "# splits the training and test data set in 80% : 20%\n",
    "# assign random_state to any value.This ensures consistency.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.4535600939850745\n",
      "R2 score is 0.8069022125298158\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.40541316382029674\n",
      "R2 score is 0.772829262603884\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "r2 = r2_score(y_train, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "y_test_predict = lin_model.predict(X_test)\n",
    "# root mean square error of the model\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "# r-squared score of the model\n",
    "r2 = r2_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the y_test vs y_pred\n",
    "# ideally should have been a straight line\n",
    "plt.scatter(y_test, y_test_predict)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the Polynomial Regression with degree 2 and test.\n",
    "\n",
    "To generate the higher order degrees, we use PolyniomialFeatures class from sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def polynomial_regression_model(degree):\n",
    "  \"Creates a polynomial regression model for the given degree\"\n",
    "  poly_features = PolynomialFeatures(degree=degree)\n",
    "  \n",
    "  # transform the features to higher degree features.\n",
    "  X_train_poly = poly_features.fit_transform(X_train)\n",
    "  \n",
    "  # fit the transformed features to Linear Regression\n",
    "  poly_model = LinearRegression()\n",
    "  poly_model.fit(X_train_poly, y_train)\n",
    "  \n",
    "  # predicting on training data-set\n",
    "  y_train_predicted = poly_model.predict(X_train_poly)\n",
    "  \n",
    "  # predicting on test data-set\n",
    "  y_test_predict = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "  \n",
    "  # evaluating the model on training dataset\n",
    "  rmse_train = np.sqrt(mean_squared_error(y_train, y_train_predicted))\n",
    "  r2_train = r2_score(y_train, y_train_predicted)\n",
    "  \n",
    "  # evaluating the model on test dataset\n",
    "  rmse_test = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
    "  r2_test = r2_score(y_test, y_test_predict)\n",
    "  \n",
    "  print(\"The model performance for the training set\")\n",
    "  print(\"-------------------------------------------\")\n",
    "  print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "  print(\"R2 score of training set is {}\".format(r2_train))\n",
    "  \n",
    "  print(\"\\n\")\n",
    "  print(\"The model performance for the test set\")\n",
    "  print(\"-------------------------------------------\")\n",
    "  print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "  print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for the training set\n",
      "-------------------------------------------\n",
      "RMSE of training set is 0.42904975210889146\n",
      "R2 score of training set is 0.8272082770286167\n",
      "\n",
      "\n",
      "The model performance for the test set\n",
      "-------------------------------------------\n",
      "RMSE of test set is 0.4071697317313779\n",
      "R2 score of test set is 0.7708564341794006\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
